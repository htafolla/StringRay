/**
 * StringRay AI v1.1.1 - Enterprise Monitoring Configuration
 *
 * Configuration templates and deployment guides for enterprise-scale monitoring.
 *
 * @version 1.0.0
 * @since 2026-01-08
 */
import { EnterpriseMonitoringConfig } from "./enterprise-monitoring";
/**
 * Basic enterprise monitoring configuration
 * Suitable for small to medium deployments
 */
export declare const basicEnterpriseConfig: Partial<EnterpriseMonitoringConfig>;
/**
 * Advanced enterprise monitoring configuration
 * Suitable for large-scale production deployments
 */
export declare const advancedEnterpriseConfig: EnterpriseMonitoringConfig;
/**
 * Docker Compose configuration for enterprise monitoring
 */
export declare const dockerComposeConfig = "\nversion: '3.8'\nservices:\n  strray:\n    image: strray/strray:v1.1.1\n    environment:\n      - NODE_ENV=production\n      - STRRAY_INSTANCE_ID=strray-1\n      - STRRAY_CLUSTER_SIZE=3\n      - LOAD_BALANCER_PROVIDER=nginx\n      - AUTO_SCALING_PROVIDER=aws\n      - PROMETHEUS_ENDPOINT=http://prometheus:9090\n      - DATADOG_API_KEY=${DATADOG_API_KEY}\n      - NEW_RELIC_LICENSE_KEY=${NEW_RELIC_LICENSE_KEY}\n      - SLACK_WEBHOOK_URL=${SLACK_WEBHOOK_URL}\n      - PAGERDUTY_INTEGRATION_KEY=${PAGERDUTY_INTEGRATION_KEY}\n    depends_on:\n      - prometheus\n      - grafana\n    networks:\n      - monitoring\n\n  prometheus:\n    image: prom/prometheus:latest\n    volumes:\n      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml\n      - prometheus_data:/prometheus\n    command:\n      - '--config.file=/etc/prometheus/prometheus.yml'\n      - '--storage.tsdb.path=/prometheus'\n      - '--web.console.libraries=/etc/prometheus/console_libraries'\n      - '--web.console.templates=/etc/prometheus/consoles'\n      - '--storage.tsdb.retention.time=200h'\n      - '--web.enable-lifecycle'\n    networks:\n      - monitoring\n\n  grafana:\n    image: grafana/grafana:latest\n    environment:\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD}\n      - GF_USERS_ALLOW_SIGN_UP=false\n    volumes:\n      - grafana_data:/var/lib/grafana\n      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning\n      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards\n    networks:\n      - monitoring\n\n  nginx:\n    image: nginx:alpine\n    volumes:\n      - ./monitoring/nginx/nginx.conf:/etc/nginx/nginx.conf\n      - ./monitoring/nginx/conf.d:/etc/nginx/conf.d\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    depends_on:\n      - strray\n    networks:\n      - monitoring\n\nnetworks:\n  monitoring:\n    driver: bridge\n\nvolumes:\n  prometheus_data:\n  grafana_data:\n";
/**
 * Kubernetes deployment configuration
 */
export declare const kubernetesConfig = "\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: strray-enterprise\n  labels:\n    app: strray\n    component: enterprise-monitor\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: strray\n  template:\n    metadata:\n      labels:\n        app: strray\n        component: enterprise-monitor\n    spec:\n      containers:\n      - name: strray\n        image: strray/strray:v1.1.1\n        env:\n        - name: NODE_ENV\n          value: \"production\"\n        - name: STRRAY_INSTANCE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        - name: STRRAY_CLUSTER_SIZE\n          value: \"3\"\n        - name: LOAD_BALANCER_PROVIDER\n          value: \"kubernetes\"\n        - name: AUTO_SCALING_PROVIDER\n          value: \"kubernetes\"\n        - name: PROMETHEUS_ENDPOINT\n          value: \"http://prometheus.monitoring:9090\"\n        envFrom:\n        - secretRef:\n            name: strray-secrets\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 3000\n          initialDelaySeconds: 30\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /ready\n            port: 3000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n        resources:\n          requests:\n            memory: \"512Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n      - name: datadog-agent\n        image: datadog/agent:latest\n        env:\n        - name: DD_API_KEY\n          valueFrom:\n            secretKeyRef:\n              name: datadog-secret\n              key: api-key\n        - name: DD_SITE\n          value: \"datadoghq.com\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: strray-service\n  labels:\n    app: strray\nspec:\n  selector:\n    app: strray\n  ports:\n  - name: http\n    port: 80\n    targetPort: 3000\n  - name: metrics\n    port: 9090\n    targetPort: 9090\n  type: LoadBalancer\n---\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: strray-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: strray-enterprise\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 75\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 80\n";
/**
 * AWS CloudFormation template for enterprise monitoring
 */
export declare const cloudFormationTemplate = "\nAWSTemplateFormatVersion: '2010-09-09'\nDescription: 'StringRay Enterprise Monitoring Stack'\n\nParameters:\n  InstanceType:\n    Type: String\n    Default: t3.medium\n    Description: EC2 instance type for StringRay instances\n\n  MinInstances:\n    Type: Number\n    Default: 2\n    Description: Minimum number of instances\n\n  MaxInstances:\n    Type: Number\n    Default: 10\n    Description: Maximum number of instances\n\nResources:\n  StringRayAutoScalingGroup:\n    Type: AWS::AutoScaling::AutoScalingGroup\n    Properties:\n      AutoScalingGroupName: strray-enterprise-asg\n      LaunchTemplate:\n        LaunchTemplateId: !Ref StringRayLaunchTemplate\n        Version: !GetAtt StringRayLaunchTemplate.LatestVersionNumber\n      MinSize: !Ref MinInstances\n      MaxSize: !Ref MaxInstances\n      DesiredCapacity: !Ref MinInstances\n      TargetGroupARNs:\n        - !Ref StringRayTargetGroup\n      HealthCheckType: ELB\n      HealthCheckGracePeriod: 300\n\n  StringRayLaunchTemplate:\n    Type: AWS::EC2::LaunchTemplate\n    Properties:\n      LaunchTemplateName: strray-enterprise-lt\n      LaunchTemplateData:\n        ImageId: ami-12345678  # Replace with actual AMI\n        InstanceType: !Ref InstanceType\n        SecurityGroupIds:\n          - !Ref StringRaySecurityGroup\n        UserData:\n          Fn::Base64: |\n            #!/bin/bash\n            yum update -y\n            # Install Docker, StringRay, monitoring agents\n            systemctl start docker\n            docker run -d --name strray strray/strray:v1.1.1\n\n  StringRayLoadBalancer:\n    Type: AWS::ElasticLoadBalancingV2::LoadBalancer\n    Properties:\n      Name: strray-enterprise-alb\n      Type: application\n      SecurityGroups:\n        - !Ref StringRaySecurityGroup\n\n  StringRayTargetGroup:\n    Type: AWS::ElasticLoadBalancingV2::TargetGroup\n    Properties:\n      Name: strray-enterprise-tg\n      Protocol: HTTP\n      Port: 80\n      VpcId: !Ref VPC\n      HealthCheckPath: /health\n      HealthCheckIntervalSeconds: 30\n      HealthyThresholdCount: 2\n      UnhealthyThresholdCount: 2\n\n  StringRayScalingPolicy:\n    Type: AWS::AutoScaling::ScalingPolicy\n    Properties:\n      AutoScalingGroupName: !Ref StringRayAutoScalingGroup\n      PolicyType: TargetTrackingScaling\n      TargetTrackingConfiguration:\n        PredefinedMetricSpecification:\n          PredefinedMetricType: ASGAverageCPUUtilization\n        TargetValue: 75.0\n\n  StringRaySecurityGroup:\n    Type: AWS::EC2::SecurityGroup\n    Properties:\n      GroupDescription: Security group for StringRay instances\n      VpcId: !Ref VPC\n      SecurityGroupIngress:\n        - IpProtocol: tcp\n          FromPort: 80\n          ToPort: 80\n          CidrIp: 0.0.0.0/0\n        - IpProtocol: tcp\n          FromPort: 443\n          ToPort: 443\n          CidrIp: 0.0.0.0/0\n";
/**
 * Grafana dashboard configuration for StringRay enterprise monitoring
 */
export declare const grafanaDashboardConfig = "\n{\n  \"dashboard\": {\n    \"title\": \"StringRay Enterprise Monitoring\",\n    \"tags\": [\"strray\", \"enterprise\", \"monitoring\"],\n    \"timezone\": \"browser\",\n    \"panels\": [\n      {\n        \"title\": \"Cluster Health Overview\",\n        \"type\": \"stat\",\n        \"targets\": [\n          {\n            \"expr\": \"up{job=\\\"strray\\\"}\",\n            \"legendFormat\": \"Healthy Instances\"\n          }\n        ],\n        \"fieldConfig\": {\n          \"defaults\": {\n            \"mappings\": [\n              {\n                \"options\": {\n                  \"0\": {\n                    \"text\": \"DOWN\",\n                    \"color\": \"red\"\n                  },\n                  \"1\": {\n                    \"text\": \"UP\",\n                    \"color\": \"green\"\n                  }\n                },\n                \"type\": \"value\"\n              }\n            ]\n          }\n        }\n      },\n      {\n        \"title\": \"System Performance\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"rate(process_cpu_user_seconds_total{job=\\\"strray\\\"}[5m]) * 100\",\n            \"legendFormat\": \"CPU Usage %\"\n          },\n          {\n            \"expr\": \"process_resident_memory_bytes{job=\\\"strray\\\"} / 1024 / 1024\",\n            \"legendFormat\": \"Memory Usage MB\"\n          }\n        ]\n      },\n      {\n        \"title\": \"Application Metrics\",\n        \"type\": \"graph\",\n        \"targets\": [\n          {\n            \"expr\": \"strray_sessions_active\",\n            \"legendFormat\": \"Active Sessions\"\n          },\n          {\n            \"expr\": \"rate(strray_tasks_completed_total[5m])\",\n            \"legendFormat\": \"Tasks per Second\"\n          },\n          {\n            \"expr\": \"strray_performance_error_rate\",\n            \"legendFormat\": \"Error Rate %\"\n          }\n        ]\n      },\n      {\n        \"title\": \"AI Agent Performance\",\n        \"type\": \"table\",\n        \"targets\": [\n          {\n            \"expr\": \"strray_agent_response_time{quantile=\\\"0.95\\\"}\",\n            \"legendFormat\": \"{{agent_id}} P95 Response Time\"\n          },\n          {\n            \"expr\": \"rate(strray_agent_tasks_failed_total[5m]) / rate(strray_agent_tasks_total[5m]) * 100\",\n            \"legendFormat\": \"{{agent_id}} Error Rate %\"\n          }\n        ]\n      }\n    ],\n    \"time\": {\n      \"from\": \"now-1h\",\n      \"to\": \"now\"\n    },\n    \"refresh\": \"30s\"\n  }\n}\n";
/**
 * Prometheus alerting rules for StringRay enterprise monitoring
 */
export declare const prometheusAlertingRules = "\ngroups:\n  - name: strray-enterprise\n    rules:\n      - alert: StringRayInstanceDown\n        expr: up{job=\"strray\"} == 0\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"StringRay instance {{ $labels.instance }} is down\"\n          description: \"StringRay instance {{ $labels.instance }} has been down for more than 5 minutes.\"\n\n      - alert: StringRayHighCPUUsage\n        expr: rate(process_cpu_user_seconds_total{job=\"strray\"}[5m]) * 100 > 85\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High CPU usage on {{ $labels.instance }}\"\n          description: \"CPU usage is {{ $value }}% for more than 10 minutes.\"\n\n      - alert: StringRayHighMemoryUsage\n        expr: process_resident_memory_bytes{job=\"strray\"} / process_virtual_memory_max_bytes > 0.9\n        for: 5m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"High memory usage on {{ $labels.instance }}\"\n          description: \"Memory usage is above 90% for more than 5 minutes.\"\n\n      - alert: StringRayHighErrorRate\n        expr: rate(strray_errors_total[5m]) / rate(strray_requests_total[5m]) > 0.05\n        for: 5m\n        labels:\n          severity: error\n        annotations:\n          summary: \"High error rate on {{ $labels.instance }}\"\n          description: \"Error rate is {{ $value }}% for more than 5 minutes.\"\n\n      - alert: StringRaySlowResponseTime\n        expr: histogram_quantile(0.95, rate(strray_request_duration_seconds_bucket[5m])) > 5\n        for: 10m\n        labels:\n          severity: warning\n        annotations:\n          summary: \"Slow response time on {{ $labels.instance }}\"\n          description: \"95th percentile response time is {{ $value }}s for more than 10 minutes.\"\n\n      - alert: StringRayAgentFailures\n        expr: increase(strray_agent_task_failures_total[10m]) > 10\n        for: 5m\n        labels:\n          severity: error\n        annotations:\n          summary: \"High agent task failure rate\"\n          description: \"Agent task failures increased by {{ $value }} in the last 10 minutes.\"\n\n      - alert: StringRayClusterUnhealthy\n        expr: count(up{job=\"strray\"} == 1) / count(up{job=\"strray\"}) < 0.5\n        for: 5m\n        labels:\n          severity: critical\n        annotations:\n          summary: \"StringRay cluster is unhealthy\"\n          description: \"Less than 50% of cluster instances are healthy.\"\n";
//# sourceMappingURL=enterprise-monitoring-config.d.ts.map